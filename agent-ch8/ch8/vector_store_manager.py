#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å‘é‡æ•°æ®åº“ç®¡ç†å·¥å…·
ä½¿ç”¨Chromaå­˜å‚¨åˆ†å‰²åçš„è…¾è®¯äº‘IMæ–‡æ¡£ï¼Œå¹¶ä½¿ç”¨TencentLKEEmbeddingsè¿›è¡Œå‘é‡åŒ–
"""

import json
import os
from typing import List, Dict, Optional
from langchain_core.documents import Document
from langchain_chroma import Chroma
from tencent_embeddings import TencentLKEEmbeddings
from document_splitter import read_and_split_document


class TencentIMVectorStore:
    """è…¾è®¯äº‘IMæ–‡æ¡£å‘é‡å­˜å‚¨ç®¡ç†å™¨"""
    
    def __init__(self, secret_id: str, secret_key: str, db_name: str = "tencent.im.db"):
        """
        åˆå§‹åŒ–å‘é‡å­˜å‚¨ç®¡ç†å™¨
        
        Args:
            secret_id (str): è…¾è®¯äº‘APIå¯†é’¥ID
            secret_key (str): è…¾è®¯äº‘APIå¯†é’¥Key
            db_name (str): å‘é‡æ•°æ®åº“åç§°
        """
        self.db_name = db_name
        self.persist_directory = f"./{db_name}"
        
        # åˆå§‹åŒ–è…¾è®¯äº‘åµŒå…¥æ¨¡å‹
        self.embeddings = TencentLKEEmbeddings(
            secret_id=secret_id,
            secret_key=secret_key,
            region="ap-guangzhou"
        )
        
        # åˆå§‹åŒ–æˆ–åŠ è½½å‘é‡æ•°æ®åº“
        self.vectorstore = None
        self._initialize_vectorstore()
    
    def _initialize_vectorstore(self):
        """åˆå§‹åŒ–å‘é‡æ•°æ®åº“"""
        try:
            if os.path.exists(self.persist_directory):
                print(f"ğŸ“‚ åŠ è½½å·²å­˜åœ¨çš„å‘é‡æ•°æ®åº“: {self.db_name}")
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embeddings
                )
            else:
                print(f"ğŸ†• åˆ›å»ºæ–°çš„å‘é‡æ•°æ®åº“: {self.db_name}")
                # å…ˆåˆ›å»ºä¸€ä¸ªç©ºçš„å‘é‡æ•°æ®åº“
                self.vectorstore = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embeddings
                )
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–å‘é‡æ•°æ®åº“å¤±è´¥: {e}")
            raise
    
    def chunks_to_documents(self, chunks: List[Dict]) -> List[Document]:
        """
        å°†æ–‡æ¡£å—è½¬æ¢ä¸ºLangchain Documentæ ¼å¼
        
        Args:
            chunks (List[Dict]): æ–‡æ¡£å—åˆ—è¡¨
            
        Returns:
            List[Document]: Langchain Documentåˆ—è¡¨
        """
        documents = []
        
        for i, chunk in enumerate(chunks):
            # åˆ›å»ºDocumentå¯¹è±¡
            doc = Document(
                page_content=chunk['content'],
                metadata={
                    'chunk_id': f"tencent_im_{i:03d}",
                    'title': chunk['title'],
                    'level': chunk['level'],
                    'start_line': chunk['start_line'],
                    'end_line': chunk['end_line'],
                    'char_count': chunk['char_count'],
                    'word_count': chunk['word_count'],
                    'source': 'tencent_im_docs',
                    'chunk_index': i
                }
            )
            documents.append(doc)
        
        return documents
    
    def add_documents_to_vectorstore(self, documents: List[Document], batch_size: int = 5) -> bool:
        """
        æ‰¹é‡æ·»åŠ æ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“
        
        Args:
            documents (List[Document]): æ–‡æ¡£åˆ—è¡¨
            batch_size (int): æ‰¹å¤„ç†å¤§å°ï¼ˆé¿å…APIè°ƒç”¨è¿‡äºé¢‘ç¹ï¼‰
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            print(f"ğŸ“ å¼€å§‹å‘é‡åŒ–å¹¶å­˜å‚¨ {len(documents)} ä¸ªæ–‡æ¡£å—...")
            
            # åˆ†æ‰¹å¤„ç†ä»¥é¿å…APIé™åˆ¶
            for i in range(0, len(documents), batch_size):
                batch = documents[i:i + batch_size]
                print(f"ğŸ”„ å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}/{(len(documents)-1)//batch_size + 1} ({len(batch)} ä¸ªæ–‡æ¡£)")
                
                # æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
                self.vectorstore.add_documents(batch)
                
                # æ·»åŠ å»¶è¿Ÿä»¥é¿å…APIé¢‘ç‡é™åˆ¶
                if i + batch_size < len(documents):
                    print("â±ï¸ ç­‰å¾…2ç§’ä»¥é¿å…APIé¢‘ç‡é™åˆ¶...")
                    import time
                    time.sleep(2)
            
            print(f"âœ… æˆåŠŸå­˜å‚¨æ‰€æœ‰æ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“ {self.db_name}")
            return True
            
        except Exception as e:
            print(f"âŒ å­˜å‚¨æ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“å¤±è´¥: {e}")
            return False
    
    def search_similar_documents(self, query: str, k: int = 5) -> List[Dict]:
        """
        æœç´¢ç›¸ä¼¼æ–‡æ¡£
        
        Args:
            query (str): æŸ¥è¯¢æ–‡æœ¬
            k (int): è¿”å›çš„æ–‡æ¡£æ•°é‡
            
        Returns:
            List[Dict]: ç›¸ä¼¼æ–‡æ¡£åˆ—è¡¨
        """
        try:
            print(f"ğŸ” æœç´¢æŸ¥è¯¢: '{query}'")
            
            # æ‰§è¡Œç›¸ä¼¼æ€§æœç´¢
            results = self.vectorstore.similarity_search_with_score(query, k=k)
            
            search_results = []
            for doc, score in results:
                result = {
                    'content': doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content,
                    'full_content': doc.page_content,
                    'metadata': doc.metadata,
                    'similarity_score': float(score),
                    'title': doc.metadata.get('title', 'Unknown')
                }
                search_results.append(result)
            
            return search_results
            
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            return []
    
    def get_database_info(self) -> Dict:
        """
        è·å–æ•°æ®åº“ä¿¡æ¯
        
        Returns:
            Dict: æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            # è·å–æ‰€æœ‰æ–‡æ¡£
            all_docs = self.vectorstore.get()
            
            info = {
                'database_name': self.db_name,
                'persist_directory': self.persist_directory,
                'total_documents': len(all_docs['ids']) if all_docs['ids'] else 0,
                'embedding_model': 'TencentLKEEmbeddings',
                'database_exists': os.path.exists(self.persist_directory)
            }
            
            return info
            
        except Exception as e:
            print(f"âŒ è·å–æ•°æ®åº“ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    def delete_database(self) -> bool:
        """
        åˆ é™¤æ•°æ®åº“
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸåˆ é™¤
        """
        try:
            import shutil
            if os.path.exists(self.persist_directory):
                shutil.rmtree(self.persist_directory)
                print(f"ğŸ—‘ï¸ å·²åˆ é™¤æ•°æ®åº“: {self.db_name}")
                return True
            else:
                print(f"âš ï¸ æ•°æ®åº“ä¸å­˜åœ¨: {self.db_name}")
                return False
        except Exception as e:
            print(f"âŒ åˆ é™¤æ•°æ®åº“å¤±è´¥: {e}")
            return False


def create_vectorstore_from_markdown(
    markdown_file: str,
    secret_id: str,
    secret_key: str,
    db_name: str = "tencent.im.db"
) -> TencentIMVectorStore:
    """
    ä»Markdownæ–‡ä»¶åˆ›å»ºå‘é‡æ•°æ®åº“
    
    Args:
        markdown_file (str): Markdownæ–‡ä»¶è·¯å¾„
        secret_id (str): è…¾è®¯äº‘APIå¯†é’¥ID
        secret_key (str): è…¾è®¯äº‘APIå¯†é’¥Key
        db_name (str): æ•°æ®åº“åç§°
        
    Returns:
        TencentIMVectorStore: å‘é‡å­˜å‚¨ç®¡ç†å™¨
    """
    print(f"ğŸš€ å¼€å§‹åˆ›å»ºå‘é‡æ•°æ®åº“: {db_name}")
    
    # 1. è¯»å–å’Œåˆ†å‰²æ–‡æ¡£
    print("ğŸ“– è¯»å–å’Œåˆ†å‰²Markdownæ–‡æ¡£...")
    chunks = read_and_split_document(markdown_file, "###")
    
    if not chunks:
        raise ValueError("æ— æ³•è¯»å–æˆ–åˆ†å‰²æ–‡æ¡£")
    
    print(f"ğŸ“„ æˆåŠŸåˆ†å‰²å‡º {len(chunks)} ä¸ªæ–‡æ¡£å—")
    
    # 2. åˆå§‹åŒ–å‘é‡å­˜å‚¨ç®¡ç†å™¨
    print("ğŸ”§ åˆå§‹åŒ–å‘é‡å­˜å‚¨ç®¡ç†å™¨...")
    vector_manager = TencentIMVectorStore(
        secret_id=secret_id,
        secret_key=secret_key,
        db_name=db_name
    )
    
    # 3. è½¬æ¢ä¸ºDocumentæ ¼å¼
    print("ğŸ“ è½¬æ¢æ–‡æ¡£æ ¼å¼...")
    documents = vector_manager.chunks_to_documents(chunks)
    
    # 4. å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
    print("ğŸ’¾ å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“...")
    success = vector_manager.add_documents_to_vectorstore(documents, batch_size=3)
    
    if success:
        print(f"âœ… å‘é‡æ•°æ®åº“ {db_name} åˆ›å»ºæˆåŠŸï¼")
    else:
        print(f"âŒ å‘é‡æ•°æ®åº“ {db_name} åˆ›å»ºå¤±è´¥ï¼")
    
    return vector_manager


def demo_vectorstore_operations():
    """
    æ¼”ç¤ºå‘é‡æ•°æ®åº“æ“ä½œ
    """
    print("ğŸ¯ è…¾è®¯äº‘IMæ–‡æ¡£å‘é‡æ•°æ®åº“æ¼”ç¤º")
    print("=" * 60)
    
    # é…ç½®ä¿¡æ¯ï¼ˆéœ€è¦æ›¿æ¢ä¸ºå®é™…çš„å¯†é’¥ï¼‰
    SECRET_ID = "your_secret_id_here"  # è¯·æ›¿æ¢ä¸ºå®é™…çš„å¯†é’¥
    SECRET_KEY = "your_secret_key_here"  # è¯·æ›¿æ¢ä¸ºå®é™…çš„å¯†é’¥
    DB_NAME = "tencent.im.db"
    MARKDOWN_FILE = "/Users/zhangtianqi/git_root/agent_homework/ch8/è…¾è®¯äº‘IMç¾¤ç»„ç³»ç»Ÿå®Œæ•´æ–‡æ¡£.md"
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›¿æ¢å¯†é’¥
    if SECRET_ID == "your_secret_id_here":
        print("âš ï¸ è¯·åœ¨ä»£ç ä¸­è®¾ç½®æ­£ç¡®çš„è…¾è®¯äº‘APIå¯†é’¥")
        print("ğŸ’¡ ä¿®æ”¹ SECRET_ID å’Œ SECRET_KEY å˜é‡")
        return
    
    try:
        # 1. åˆ›å»ºå‘é‡æ•°æ®åº“
        vector_manager = create_vectorstore_from_markdown(
            markdown_file=MARKDOWN_FILE,
            secret_id=SECRET_ID,
            secret_key=SECRET_KEY,
            db_name=DB_NAME
        )
        
        # 2. æ˜¾ç¤ºæ•°æ®åº“ä¿¡æ¯
        print("\nğŸ“Š æ•°æ®åº“ä¿¡æ¯:")
        info = vector_manager.get_database_info()
        for key, value in info.items():
            print(f"   {key}: {value}")
        
        # 3. æ¼”ç¤ºæœç´¢åŠŸèƒ½
        print("\nğŸ” æœç´¢æ¼”ç¤º:")
        test_queries = [
            "ç›´æ’­ç¾¤æœ‰ä»€ä¹ˆç‰¹ç‚¹",
            "å¦‚ä½•è®¾ç½®ç¾¤ç»„æƒé™",
            "ç¾¤æˆå‘˜ç®¡ç†åŠŸèƒ½",
            "ç¤¾ç¾¤Communityçš„ä¼˜åŠ¿"
        ]
        
        for query in test_queries:
            print(f"\næŸ¥è¯¢: '{query}'")
            results = vector_manager.search_similar_documents(query, k=3)
            
            for i, result in enumerate(results):
                print(f"  {i+1}. {result['title']} (ç›¸ä¼¼åº¦: {result['similarity_score']:.4f})")
                print(f"     å†…å®¹é¢„è§ˆ: {result['content'][:100]}...")
    
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")


if __name__ == "__main__":
    demo_vectorstore_operations()