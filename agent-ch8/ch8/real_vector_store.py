#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çœŸå®çš„è…¾è®¯äº‘IMæ–‡æ¡£å‘é‡æ•°æ®åº“
ä½¿ç”¨TencentLKEEmbeddingsè¿›è¡Œå‘é‡åŒ–å­˜å‚¨
"""

import json
import os
import time
from typing import List, Dict
from langchain_core.documents import Document
from langchain_chroma import Chroma
from tencent_embeddings import TencentLKEEmbeddings
from document_splitter import read_and_split_document


class TencentIMVectorDatabase:
    """è…¾è®¯äº‘IMæ–‡æ¡£å‘é‡æ•°æ®åº“ç®¡ç†å™¨"""
    
    def __init__(self, secret_id: str, secret_key: str, db_name: str = "tencent.im.db"):
        """
        åˆå§‹åŒ–å‘é‡æ•°æ®åº“ç®¡ç†å™¨
        
        Args:
            secret_id (str): è…¾è®¯äº‘APIå¯†é’¥ID
            secret_key (str): è…¾è®¯äº‘APIå¯†é’¥Key
            db_name (str): æ•°æ®åº“åç§°
        """
        self.secret_id = secret_id
        self.secret_key = secret_key
        self.db_name = db_name
        self.persist_directory = f"./{db_name}"
        
        # åˆå§‹åŒ–è…¾è®¯äº‘åµŒå…¥æ¨¡å‹
        print("ğŸ”§ åˆå§‹åŒ–TencentLKEEmbeddings...")
        self.embeddings = TencentLKEEmbeddings(
            secret_id=secret_id,
            secret_key=secret_key,
            region="ap-guangzhou"
        )
        
        # å‘é‡æ•°æ®åº“å®ä¾‹
        self.vectorstore = None
    
    def create_database_from_markdown(self, markdown_file: str, batch_size: int = 3) -> bool:
        """
        ä»Markdownæ–‡ä»¶åˆ›å»ºå‘é‡æ•°æ®åº“
        
        Args:
            markdown_file (str): Markdownæ–‡ä»¶è·¯å¾„
            batch_size (int): æ‰¹å¤„ç†å¤§å°ï¼ˆé¿å…APIé¢‘ç‡é™åˆ¶ï¼‰
            
        Returns:
            bool: æ˜¯å¦åˆ›å»ºæˆåŠŸ
        """
        try:
            print(f"ğŸš€ å¼€å§‹åˆ›å»ºå‘é‡æ•°æ®åº“: {self.db_name}")
            
            # 1. è¯»å–å’Œåˆ†å‰²æ–‡æ¡£
            print("ğŸ“– è¯»å–å’Œåˆ†å‰²Markdownæ–‡æ¡£...")
            chunks = read_and_split_document(markdown_file, "###")
            
            if not chunks:
                print("âŒ æ— æ³•è¯»å–æˆ–åˆ†å‰²æ–‡æ¡£")
                return False
            
            print(f"ğŸ“„ æˆåŠŸåˆ†å‰²å‡º {len(chunks)} ä¸ªæ–‡æ¡£å—")
            
            # 2. è½¬æ¢ä¸ºDocumentæ ¼å¼
            print("ğŸ“ è½¬æ¢ä¸ºLangchain Documentæ ¼å¼...")
            documents = self._chunks_to_documents(chunks)
            print(f"âœ… è½¬æ¢äº† {len(documents)} ä¸ªæ–‡æ¡£")
            
            # 3. åˆ é™¤å·²å­˜åœ¨çš„æ•°æ®åº“
            if os.path.exists(self.persist_directory):
                import shutil
                shutil.rmtree(self.persist_directory)
                print(f"ğŸ—‘ï¸ åˆ é™¤å·²å­˜åœ¨çš„æ•°æ®åº“: {self.db_name}")
            
            # 4. åˆ†æ‰¹åˆ›å»ºå‘é‡æ•°æ®åº“ï¼ˆé¿å…APIé¢‘ç‡é™åˆ¶ï¼‰
            print(f"ğŸ’¾ å¼€å§‹å‘é‡åŒ–å¹¶åˆ›å»ºæ•°æ®åº“ï¼ˆæ‰¹æ¬¡å¤§å°: {batch_size}ï¼‰...")
            
            # å¤„ç†ç¬¬ä¸€æ‰¹ï¼Œåˆ›å»ºæ•°æ®åº“
            first_batch = documents[:batch_size]
            print(f"ğŸ”„ å¤„ç†ç¬¬1æ‰¹ ({len(first_batch)} ä¸ªæ–‡æ¡£)")
            
            self.vectorstore = Chroma.from_documents(
                documents=first_batch,
                embedding=self.embeddings,
                persist_directory=self.persist_directory
            )
            
            # å¤„ç†å‰©ä½™æ‰¹æ¬¡
            remaining_docs = documents[batch_size:]
            if remaining_docs:
                for i in range(0, len(remaining_docs), batch_size):
                    batch_num = i // batch_size + 2
                    batch = remaining_docs[i:i + batch_size]
                    
                    print(f"ğŸ”„ å¤„ç†ç¬¬{batch_num}æ‰¹ ({len(batch)} ä¸ªæ–‡æ¡£)")
                    
                    # æ·»åŠ åˆ°ç°æœ‰æ•°æ®åº“
                    self.vectorstore.add_documents(batch)
                    
                    # æ·»åŠ å»¶è¿Ÿé¿å…APIé¢‘ç‡é™åˆ¶
                    if i + batch_size < len(remaining_docs):
                        print("â±ï¸ ç­‰å¾…3ç§’ä»¥é¿å…APIé¢‘ç‡é™åˆ¶...")
                        time.sleep(3)
            
            print(f"âœ… å‘é‡æ•°æ®åº“ {self.db_name} åˆ›å»ºæˆåŠŸï¼")
            return True
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºå‘é‡æ•°æ®åº“å¤±è´¥: {e}")
            return False
    
    def load_existing_database(self) -> bool:
        """
        åŠ è½½å·²å­˜åœ¨çš„å‘é‡æ•°æ®åº“
        
        Returns:
            bool: æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        try:
            if not os.path.exists(self.persist_directory):
                print(f"âŒ æ•°æ®åº“ä¸å­˜åœ¨: {self.db_name}")
                return False
            
            print(f"ğŸ“‚ åŠ è½½å·²å­˜åœ¨çš„å‘é‡æ•°æ®åº“: {self.db_name}")
            self.vectorstore = Chroma(
                persist_directory=self.persist_directory,
                embedding_function=self.embeddings
            )
            
            print(f"âœ… æ•°æ®åº“åŠ è½½æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®åº“å¤±è´¥: {e}")
            return False
    
    def search_documents(self, query: str, k: int = 5) -> List[Dict]:
        """
        æœç´¢ç›¸ä¼¼æ–‡æ¡£
        
        Args:
            query (str): æŸ¥è¯¢æ–‡æœ¬
            k (int): è¿”å›æ–‡æ¡£æ•°é‡
            
        Returns:
            List[Dict]: æœç´¢ç»“æœ
        """
        if not self.vectorstore:
            print("âŒ å‘é‡æ•°æ®åº“æœªåˆå§‹åŒ–")
            return []
        
        try:
            print(f"ğŸ” æœç´¢æŸ¥è¯¢: '{query}'")
            
            # æ‰§è¡Œç›¸ä¼¼æ€§æœç´¢
            results = self.vectorstore.similarity_search_with_score(query, k=k)
            
            search_results = []
            for doc, score in results:
                result = {
                    'title': doc.metadata.get('title', 'Unknown'),
                    'content_preview': doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content,
                    'full_content': doc.page_content,
                    'metadata': doc.metadata,
                    'similarity_score': float(1 - score),  # è½¬æ¢ä¸ºç›¸ä¼¼åº¦
                    'distance_score': float(score)
                }
                search_results.append(result)
            
            return search_results
            
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            return []
    
    def get_database_info(self) -> Dict:
        """
        è·å–æ•°æ®åº“ä¿¡æ¯
        
        Returns:
            Dict: æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            if not self.vectorstore:
                return {'error': 'æ•°æ®åº“æœªåˆå§‹åŒ–'}
            
            all_docs = self.vectorstore.get()
            total_docs = len(all_docs['ids']) if all_docs['ids'] else 0
            
            # è®¡ç®—æ•°æ®åº“å¤§å°
            db_size = self._get_folder_size(self.persist_directory)
            
            info = {
                'database_name': self.db_name,
                'persist_directory': self.persist_directory,
                'total_documents': total_docs,
                'embedding_model': 'TencentLKEEmbeddings',
                'database_size_mb': round(db_size, 2),
                'database_exists': os.path.exists(self.persist_directory)
            }
            
            return info
            
        except Exception as e:
            return {'error': f'è·å–æ•°æ®åº“ä¿¡æ¯å¤±è´¥: {e}'}
    
    def _chunks_to_documents(self, chunks: List[Dict]) -> List[Document]:
        """å°†æ–‡æ¡£å—è½¬æ¢ä¸ºLangchain Documentæ ¼å¼"""
        documents = []
        
        for i, chunk in enumerate(chunks):
            doc = Document(
                page_content=chunk['content'],
                metadata={
                    'chunk_id': f"tencent_im_{i:03d}",
                    'title': chunk['title'],
                    'level': chunk['level'],
                    'start_line': chunk['start_line'],
                    'end_line': chunk['end_line'],
                    'char_count': chunk['char_count'],
                    'word_count': chunk['word_count'],
                    'source': 'tencent_im_docs',
                    'chunk_index': i
                }
            )
            documents.append(doc)
        
        return documents
    
    def _get_folder_size(self, folder_path: str) -> float:
        """è·å–æ–‡ä»¶å¤¹å¤§å°ï¼ˆMBï¼‰"""
        total_size = 0
        try:
            for dirpath, dirnames, filenames in os.walk(folder_path):
                for filename in filenames:
                    file_path = os.path.join(dirpath, filename)
                    total_size += os.path.getsize(file_path)
            return total_size / (1024 * 1024)
        except Exception:
            return 0.0


def demo_real_vector_store():
    """
    çœŸå®å‘é‡æ•°æ®åº“æ¼”ç¤º
    """
    print("ğŸ¯ è…¾è®¯äº‘IMæ–‡æ¡£å‘é‡æ•°æ®åº“ (çœŸå®ç‰ˆæœ¬)")
    print("=" * 60)
    
    # ç›´æ¥ä½¿ç”¨APIå¯†é’¥
    SECRET_ID = ""
    SECRET_KEY = ""
    DB_NAME = "tencent.im.db"
    MARKDOWN_FILE = "/Users/zhangtianqi/git_root/agent_homework/ch8/è…¾è®¯äº‘IMç¾¤ç»„ç³»ç»Ÿå®Œæ•´æ–‡æ¡£.md"
    
    print(f"ğŸ“– ä½¿ç”¨APIå¯†é’¥: {SECRET_ID[:10]}...")
    
    # æ£€æŸ¥APIå¯†é’¥é…ç½®
    if SECRET_ID == "your_secret_id_here" or SECRET_KEY == "your_secret_key_here":
        print("âš ï¸ è¯·é…ç½®çœŸå®çš„è…¾è®¯äº‘APIå¯†é’¥")
        print("ğŸ’¡ ä¿®æ”¹SECRET_IDå’ŒSECRET_KEYå˜é‡")
        print("ğŸ”‘ è·å–å¯†é’¥: https://console.cloud.tencent.com/cam/capi")
        return
    
    try:
        # 1. åˆå§‹åŒ–å‘é‡æ•°æ®åº“ç®¡ç†å™¨
        db_manager = TencentIMVectorDatabase(
            secret_id=SECRET_ID,
            secret_key=SECRET_KEY,
            db_name=DB_NAME
        )
        
        # 2. å°è¯•åŠ è½½å·²å­˜åœ¨çš„æ•°æ®åº“ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
        if not db_manager.load_existing_database():
            print("ğŸ“ æ•°æ®åº“ä¸å­˜åœ¨ï¼Œå¼€å§‹åˆ›å»º...")
            success = db_manager.create_database_from_markdown(MARKDOWN_FILE, batch_size=2)
            
            if not success:
                print("âŒ æ•°æ®åº“åˆ›å»ºå¤±è´¥")
                return
        
        # 3. æ˜¾ç¤ºæ•°æ®åº“ä¿¡æ¯
        print("\nğŸ“Š æ•°æ®åº“ä¿¡æ¯:")
        info = db_manager.get_database_info()
        for key, value in info.items():
            print(f"   {key}: {value}")
        
        # 4. æ¼”ç¤ºæœç´¢åŠŸèƒ½
        print("\nğŸ” æœç´¢åŠŸèƒ½æ¼”ç¤º:")
        test_queries = [
            "ç›´æ’­ç¾¤AVChatRoomçš„ç‰¹ç‚¹",
            "ç¤¾ç¾¤Communityæ”¯æŒå¤šå°‘äºº",
            "å¦‚ä½•è®¾ç½®ç¾¤ç»„æƒé™",
            "ç¾¤æˆå‘˜ç®¡ç†åŠŸèƒ½æœ‰å“ªäº›",
            "æ¶ˆæ¯å­˜å‚¨å’Œæ¼«æ¸¸è§„åˆ™"
        ]
        
        search_results = {}
        
        for query in test_queries:
            print(f"\nğŸ” æŸ¥è¯¢: '{query}'")
            results = db_manager.search_documents(query, k=3)
            
            search_results[query] = results
            
            for i, result in enumerate(results):
                print(f"   {i+1}. ğŸ“„ {result['title']}")
                print(f"      ğŸ¯ ç›¸ä¼¼åº¦: {result['similarity_score']:.4f}")
                print(f"      ğŸ“ å†…å®¹: {result['content_preview'][:80]}...")
        
        # 5. ä¿å­˜æœç´¢ç»“æœ
        output_file = "real_vector_search_results.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump({
                'database_info': info,
                'search_results': search_results
            }, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ æœç´¢ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")


def create_config_template():
    """
    åˆ›å»ºé…ç½®æ–‡ä»¶æ¨¡æ¿
    """
    config_template = {
        "tencent_cloud": {
            "secret_id": "your_secret_id_here",
            "secret_key": "your_secret_key_here",
            "region": "ap-guangzhou"
        },
        "vector_database": {
            "name": "tencent.im.db",
            "batch_size": 3,
            "embedding_model": "lke-text-embedding-v1"
        },
        "documents": {
            "source_file": "/Users/zhangtianqi/git_root/agent_homework/ch8/è…¾è®¯äº‘IMç¾¤ç»„ç³»ç»Ÿå®Œæ•´æ–‡æ¡£.md",
            "split_level": "###"
        }
    }
    
    config_file = "vector_store_config.json"
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump(config_template, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“ é…ç½®æ–‡ä»¶æ¨¡æ¿å·²åˆ›å»º: {config_file}")
    print("ğŸ’¡ è¯·ç¼–è¾‘é…ç½®æ–‡ä»¶å¹¶è®¾ç½®æ­£ç¡®çš„APIå¯†é’¥")


if __name__ == "__main__":
    print("ğŸš€ è…¾è®¯äº‘IMæ–‡æ¡£å‘é‡æ•°æ®åº“ - çœŸå®ç‰ˆæœ¬")
    print("=" * 80)
    
    # åˆ›å»ºé…ç½®æ¨¡æ¿
    create_config_template()
    
    # è¿è¡Œæ¼”ç¤º
    demo_real_vector_store()
